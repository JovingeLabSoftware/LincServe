% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/slinky.R
\docType{class}
\name{Slinky-class}
\alias{Slinky}
\alias{Slinky-class}
\title{Slinky Class}
\description{
A class to facilitate storage and analysis of the level 2 data from the LINCS project.  This
class does not provide any of the data (which must be obtained under individual agreement with
LINCS).  However, once obtained, working with their large binary data files is facilitated
by this class.
}
\details{
Make LINCS analysis fun.
}
\section{Fields}{

\describe{
\item{\code{.ip}}{(Private) IP address of your LINCS REST server, set with setIp. Default is \code{127.0.0.1}.}

\item{\code{.port}}{(Private)  Port of your LINCS REST server, set with setPort. Default is \code{8080}.}

\item{\code{loglevel}}{How much information should we log? Options are \code{all},
\code{error}, \code{warn}, \code{none}.  Note that \code{all} or \code{warn} will result in logfile ~120MB in size.
Default is \code{all}.}

\item{\code{logfile}}{Where to store the log.  Default is \code{log.txt}.}

\item{\code{silent}}{Should logging info only be written to file (and not to stdout)?  Default is FALSE.  Irrelevant if \code{loglevel} is \code{none}.}

\item{\code{maxtries}}{If http request fails, how many times should we retry before moving on? Default is \code{3}.}
}}
\section{Methods}{

\describe{
\item{\code{append(id, data, type)}}{Append data to an instance.  DATA MUST HAVE THE SAME NUMBER OF ROWS AS PRE-EXISTING
 gene_ids, AND BE IN THE SAME ORDER! 
\subsection{Parameters}{
\itemize{
\item{\code{id} The distil_id of the doc to which to append.}
\item{\code{data} The data to append.}
\item{\code{type} The type of data.  This will be the name of the new top level field to which 
      the data is saved.  E.g. 'zsvc' or 'zspc'}
}}
\subsection{Return Value}{List with metadata and data (gene expression) components}}

\item{\code{calc(filter = NULL, cores = NULL, cluster = NULL)}}{Calculate zscores and stores them in the document store. Future versions will 
 allow users to specify a \code{filter} statement to only compute a subset of
 scores.
\subsection{Parameters}{
\itemize{
\item{\code{filter} TODO: implement this.}
\item{\code{cores} Optional: an integer specifying the number of cores to parallelize calculations over with the \code{foreach} back end. This value is passed to the \code{doMC::registerDoMC} function for parallelization with \code{foreach}.}
\item{\code{cluster} Optional: a cluster object created with \code{snow::makeCluster} to parallelize calculations. The \code{cluster} object is passed to the \code{doSNOW::registerDoSNOW} function for parallelization with \code{foreach}.}
}}
\subsection{Return Value}{None.  Called for side effect of populating 
document store with zscores}}

\item{\code{getInstance(ids)}}{Retrieve instances in their entirety including all data and metadata.
Uses the POST interface of the REST API to avoid query string length 
restriction for GET queries, enabling retrieval of large(r) datasets.
\subsection{Parameters}{
\itemize{
\item{\code{ids} distil_ids for which data is desired.}
}
}}
\subsection{Return Value}{Instances in list format}}

\item{\code{getInstanceData(ids, type = "q2norm")}}{Retrieve instance data for multiple distil_ids. Uses the POST interface of the 
REST API to avoid query string length restriction for GET queries, enabling
retrieval of large(r) datasets.
\subsection{Parameters}{
\itemize{
\item{\code{ids} distil_ids for which data is desired.}
\item{\code{type} which data type you want to return.  Default is
                    q2norm, other options may include zsvc and zspc
}
}}
\subsection{Return Value}{Dataframe containing the requested data}}

\item{\code{loadLevel2(gctxfile = "/mnt/lincs/q2norm_n1328098x22268.gctx", col)}}{Load data for specified column(s) from hdf5 formatted file (.gctx) from LINCS Fetch 
into your document store via RESTful interface.  Metadata will be matched from metadata
object included in this package and added to resulting document. 
\subsection{Parameters}{
\itemize{
\item{\code{gctxfile} Path to level 2 gctx file. Default is \code{./q2norm_n1328098x22268.gctx}.}
\item{\code{col} Column(s) of data to load from gctx file.}
}}
\subsection{Return Value}{id(s) of resulting documents in doc store.}}

\item{\code{query(q, f = NA, l = NA, s = NA)}}{Retrieve metadata using the query interface of the REST API. 
\subsection{Parameters}{
\itemize{
\item{\code{q} query terms as field=value pairs in the form of a list.  Value
       may be a single value or a vector of values.  Fields are assumed to be 
       within the metadata slot of the data, so there is no need to prefix fields 
       with 'metadata.', although it is allowed.  This also means query is restricted
       to the metadata (i.e. you cannot query based on gene_ids or doctype).}
\item{\code{f} vector of fields to return.  Defaults to '*'.  Note here subfields
                 (e.g. metdata.pert_desc) must be explicit as top level fields (e.g. data)
                 can also be returned
\item{\code{l} limit, for paging (number of documents to return, default is everything)
\item{\code{s} skip, for paging (default in 0)
}}
\subsection{Return Value}{List with metadata and data (gene expression) components}}

\item{\code{setIp(ip = "127.0.0.1")}}{Set IP and redefine endpoint
\subsection{Parameters}{
\itemize{

\item{\code{ip} The IP address of the your LINCS REST server, default is \code{127.0.0.1}.}
}}
\subsection{Return Value}{none}}

\item{\code{setPort(port = "8080")}}{Set port and redefine endpoint
\subsection{Parameters}{
\itemize{
\item{\code{port} The port of the your LINCS REST server, default is \code{8080}.}
}}
\subsection{Return Value}{none}}
}}
\examples{
lincs <- Slinky$new()
lincs$calc()
}

